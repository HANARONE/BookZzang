왜 나는,, 큰 글씨가 안나오는 걸까,, 이렇게 하는게 아닌가,,? 리드미 파일 업로드 버튼 어딨어,,

# 이론정리
# chap1.

## 1.1 인공지능과 머신러닝, 딥러닝


### 인공지능
-	사람처럼 학습하고 추론할 수 있는 지능을 가진 컴퓨터 시스템을 만드는 기술
-	강인공지능: 사람과 구별하기 어려운 지능을 가진 컴퓨터시스템
-	약인공지능: 사람 일 보조 ex)음성비서, 자율주행자동차 등


### 머신러닝
-	수동으로 규칙을 입력하지 않아도 자동으로 데이터에서 규칙을 학습하는 알고리즘
-	대표 라이브러리: 사이킷런(scikit-learn)


###딥러닝
-	머신러닝 알고리즘 중 인공신경망을 기반으로 한 알고리즘
-	합성곱 신경망
-	대표 라이브러리: 텐서플로(TensorFlow), 파이토치(PyTorch)


## 1.3 마켓과 머신러닝
- 분류: 머신러닝에서 여러 개의 클래스 중 하나를 구별해내는 문제
  -	이진분류: 2개의 클래스 중 하나를 고르는 문제
- 특성: 데이터의 특징
- 산점도: x,y축으로 이루어진 좌표계에 두 변수(x,y)의 관계를 표현하는 방법
  -	matplotlib의 scatter()함수 사용
  -	산점도 그래프가 일직선에 가까운 형태로 나타나는 경우, ‘선형적’이라고 표현


- K 최근접 이웃 알고리즘
  -	Fit() 메서드: 주어진 데이터로 알고리즘 훈련
  -	Score()메서드: 사이킷런에서 모델을 평가하는 메서드
    -	0에서 1 사이의 값을 반환
    -	1에 가까울수록 정확도가 높아짐
  -	 Predict()메서드: 새로운 데이터의 정답 예측


# Chap2.


## 2.1 훈련세트와 데이터세트
머신러닝 알고리즘
-	지도학습: 데이터(입력)와 정답(타깃)으로 이루어진 훈련데이터 필요
-	테스트세트: 평가에 사용하는 데이터
-	훈련세트: 훈련에 사용되는 데이터
-	테스트 세트와 훈련세트는 따로 준비해야 정확한 평가가 가능
-	샘플링 편향: 훈련세트와 테스트 세트에 샘플이 골고루 섞여 있지 않고 한 쪽으로 치우쳐져 있을 경우


-	넘파이: 파이썬의 대표적인 배열 라이브러리
  -	Shuffle(): 주어진 배열 무작위로 섞음
  -	Column_stack(): 전달받은 리스트를 일렬로 세운 후 차례대로 나란히 연결
  -	Np.ones(), np.zeros() : 1,0으로 채워진 배열 생성
  -	Np.concatenate(): 배열 연결 함수. 첫번째 배열 뒤로 그대로 연결 
-	훈련세트와 테스트세트 나누기
  -	Trai_test_split()


## 2.2 데이터 전처리 
-	데이터 전처리를 통해 특성값을 일정한 기준으로 맞춰주기
-	표준점수(Z점수) : 각 특성값이 평균에서 표준편차의 몇 배만큼 떨어져있는지 나타내는 방법
-	브로드캐스팅: 크기가 다른 넘파이 배열에서 자동으로 사칙 연산을 모든 행이나 열로 확장하여 수행하는 기능


# chap 3. 회귀 알고리즘과 모델 규제



- k 최근접 이웃 분류: 예측하려는 샘플에 가장 가까운 샘플k개 선택-> 샘플들의 클래스를 확인하수 다수의 클래스를 새로운 샘플의 클래스로 예측
- k 최근접 이웃 회귀: 예측하려는 샘플에 가장 가까운 샘플k개 선택-> 이웃한 샘플의 타킷은 임의의 수치
- 결정계수R^2:  회귀식 성능 평가 방법
   - 예측이 타깃의 평균정도 예측하는 수준이면 0에 가깝고, 예측이 타킷에 아주 가까워지면 1에 가까운 값이 된다. 
-과대적합: 훈련세트에서는 성능이 좋았는데 테스트 세트에서는 성능이 떨어지는 경우
-과소적합: 훈련세트보다 테스트 저수가 높거나 두 점수 모두 낮은 경우
- 패키지: 
- KNeighborsRegressor: K-최근접 이웃 회귀 모델을 만드는 클래스. N은 매개변수이며 기본값은 5
- mean_absolute_erroe(): 회귀 모델의 평균 절대값 오차
- mean_squared_error(): 평균 제곱 오차


## 3.2 
### 1. 선형회귀
- 특성이 하나인 경우 직선을 학습하는 알고리즘
- 선형회귀가 찾은 특성과 타깃 사이이 관계는 선형방정식의 계수 또는 가중치에 저장
- 모델 파라미터: 모델 특성에서 학습한 파라미터
- 모델 기반 학습: 최적의 모델 파라미터를 찾는 것
- 사례 기반 학습: 모델 파라미터 없이 훈련세트를 저장하는 것
- 사용 패키지: LinearRegression
-coef_:기울기, intercept_: 절편


### 2. 다항회귀
- 다항식을 이용한 선형회귀

## 3.3 특성공학과 규제
- 특성공학: 기존의 특성을 활용해 새로운 특성을 뽑아내는 작업
- 다중회귀: 여러 개의 특성을 사용한 선형회귀
   하나의 특성만으로는 정확한 예측을 하기 어렵기 때문에 다중회귀 모델 사용
   사용 패키지: PolynomiaFeatures – 사이킷런의 클래스로, 특성을 만들어내거나 전처리하는 클래스
   하이퍼파라미터: 사람이 직접 지정해줘야 하는 파마리터. 릿지와 라쏘의 alpha 값이 이에 해당


- 규제- 과대적합 방지 기법 (선형 회귀 모델의 경우 특성에 곱해지는 계수(기울기)의 크기를 작게 만듦)
   모델 객체를 만들 때 alpha매개변수로 규제의 강도 조절
   alpha값이 커지면 규제 강도가 세지므로 계수 값을 더 줄이고, 과소적합 되도록 유도
   릿지 회귀: 선형 모델의 계수를 작게 만들어 과대적합을 완화. 라쏘는 가중치들이 0이 되지만, 릿지의 가중치들은 0에 가까워질 뿐 0이 되지는 않는다.
   사용 패키지: Ridge
   라쏘 회귀: MSE가 최소가 되게 하는 가중치와 편향을 찾으면서 동시에, 가중치들의 절댓값의 합이 최소가 되게 하는 것. 즉, 가중치의 모든 원소가 0이 되거나 0에 가깝게 되도록 해야 한다
   사용 패키지: Lasso
   
실제 분석에 적용할 때는 릿지와 라쏘 두 가지 기법을 모두 사용해보고, 더 좋은 성능을 보이는 기법을 선택한다

