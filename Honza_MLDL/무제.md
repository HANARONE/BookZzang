#### 14. Why is gradient descent needed when training a model?

Gradient descent is an optimization algorithm used to find the values of parameters (weights) that minimize a cost function. When training a model, gradient descent is used to find the values of the weights that minimize the error between the predicted values and the actual values.



#### 17. Can you explain how to perform feature scaling before running a gradient descent algorithm?

Feature scaling is the process of normalizing your data so that all features are on the same scale. This is important because if some features are on a much larger scale than others, then they will dominate the objective function and the gradient descent algorithm will have a hard time converging. There are a few different ways to perform feature scaling, but one common method is to simply subtract the mean of each feature from all of the values for that feature, and then divide by the standard deviation.



#### 19. What are the three types of gradient descent?

The three types of gradient descent are batch gradient descent, stochastic gradient descent, and mini-batch gradient descent. Batch gradient descent is the slowest and most precise method, while stochastic gradient descent is the fastest but least precise. Mini-batch gradient descent is somewhere in the middle, offering a balance of speed and accuracy.





## **What is the Gradient Descent Algorithm?**

Gradient Descent is an algorithm which is used to train most Machine Learning models and Neural Networks. It is the algorithm that reduces the error in the cost function using the training data. In doing so, it optimizes the model by increasing its accuracy and updating its parameters so that they result in the smallest possible error. It basically finds the overall minimum of the cost function, or any function.





## **Why do we need to Use the Gradient Descent algorithm?**

The reason is simple – computational efficiency. It gets the work done faster and cheaper than an approach like the Linear Algebra one. In fact, there are also iterations and types of the Gradient Descent algorithm that allow parallel (simultaneous) calculations to take place and approaches that further enhance the computational time.







#### **What is the difference between the Gradient Descent method and the Ordinary Least Squares method? Which is better?**



In Gradient descent:

- We need to perform hyper-parameter tuning for the learning parameter.
- We need to iterate.
- We have a time complexity of O(kn2)

in Ordinary Least Squares:

- There is no need for any hyperparameter.
- No iteration is needed.
- We have a time complexity of O(n3)

Looking at the above differences, it is evident that the Ordinary Least Squares method is the better and swifter option for a smaller training data (smaller n). However, for larger n (larger training data), due to the higher time complexity of the Ordinary Least Squares method, the Gradient Descent algorithm must be preferred.









#### **What are the different types of Gradient Descent methods?**



The methods are:

- Batch Gradient Descent: where the entire training data is taken into account to take a single step. Its cost function is convex and relatively smooth.
- Stochastic Gradient Descent: where only one data is taken into account to take a single step. Its cost function is a fluctuating one whose fluctuations eventually decrease as the number of iterations pass.
- Mini-batch Gradient Descent: where a batch of a fixed number of data is taken into account. Its cost function is also a fluctuation one.







#### **Name a type of Error Function used during Gradient Descent.**



MSE – Mean Squared Error function







#### **What approaches can we take to lessen the effects of overfitting?**



- Regularization: L1, L2 regularization (commonly called weight decay), ElasticNet
- Adjustment of learning rate
- Dropout (technically a type of regularization)
- Implicit Regularization: Early Stopping, Data Augmentation
- Batch Normalisation







#### **What is the difference between a global minima and a local minima?**



Local minima are peaks (troughs) across a landscape that represent many small regions of loss. Our global minimum is the local minimum with the least loss over the loss landscape. This point ensures our parameters take on the most optimal solutions.











#### **What are the problems with Vanilla Gradient Descent?**



- If the number of training samples is large, then the vanilla gradient descent is going to take a long time to converge due to the fact that a weight update is only happening once per data cycle.
- The larger your dataset, the more nuanced your gradients become, the more time related computation is used and eventually, there will not be much learning.









#### **If we have 7 independent variables and 4 feature interactions, how many of these terms will be included in the gradient calculation?**



All (11) of them. Because each given feature will have its own coefficient which determines effect or relevance of the feature on the output predictions. Although Gradient descent can weaken or diminish or strengthen the effects of these features.







#### **Outline Gradient Descent Optimization Algorithms**



- Momentum: It helps accelerate Stochastic Gradient Descent in the relevant direction and dampens irregular movements of the SGD as it navigates to the local optimum.

- Nesterov Accelerated Gradient: This method works directly with Momentum. In layman’s terms, it makes the descent smarter. Typically, the momentum first computes the gradient and then makes a movement in the direction of the updated accumulated current gradient. Nesterov Accelerated Gradient (NAG) also makes a movement (not as much) in the direction of the momentum (previous accumulated gradient), measures the gradient and makes a correction which results in the complete NAG update. This anticipatory update prevents us from going too fast and results in increased responsiveness which is suitable for the models.
- AdaGrad: It allows the learning rate adapt to parameters, performing smaller updates (i.e. low learning rates) for parameters associated with frequently occurring features and larger updates (i.e large learning rates) for parameters associated with infrequent features With all these stated, it is suitable for dealing with sparse data.
- Adadelta: It is the extension of Adagrad that seeks to reduce its aggressive, monotonically decreasing learning rate. Adagrad accumulates squared gradients which makes the learning rate shrink to uselessness. Adadelta restricts the window of accumulated passed gradients to a particular size.
- RMSProp: It is an adaptive learning rate method that stemmed from the need to resolve Adagrad’s radically diminishing learning rates. RMSprop divides learning rate by an exponentially decaying average of squared gradients.
- Adaptive Moment Estimation (Adam): Adam is a method that computes adaptive learning rates for each parameter
- Nadam
- Adamax
- AdamW: This fixes weight decay in Adam









#### **What are the merits and demerits of Batch Gradient Descent?**



**Advantages**

- It is computationally efficient
- It has stable performance (less noise)

**Disadvantages**

- It requires a lot of memory
- It has a slower learning process
- It may become caught in local minima









## **Conclusion**

To sum it all up, the Gradient Descent algorithm is an essential part of an AI enthusiast’s knowledge. It is a fundamental part of ML and something that may seem simple, but is used extremely often and asked about equally as often as well. 





##### [What is gradient descent and is gradient descent first-order method?](https://avatto.in/data-scientist/interview-questions/deep-learning/gradient-descent-method/#shrt-collapse-1)

Gradient descent is the most popular and widely used optimization algorithms used for training neural networks. Yes, Gradient descent is the first-order optimization method because with gradient descent we calculate only the first-order derivative.







##### [How does the gradient descent method work?](https://avatto.in/data-scientist/interview-questions/deep-learning/gradient-descent-method/#shrt-collapse-2)

Gradient descent is an optimization method used for training the network. First, we compute the derivatives of the loss function with respect to the weights of the network and then update the weights of the network using the below update rule:

- **Weight = weight - learning rate x derivatives**









##### [What happens when the learning rate is small and large?](https://avatto.in/data-scientist/interview-questions/deep-learning/gradient-descent-method/#shrt-collapse-4)

When the learning rate is small then we take a very small step and it slows down attaining the convergence and when the learning rate is large then we take a very large step and it may cause us to miss out on the global minimum.







##### [What is the need for gradient checking?](https://avatto.in/data-scientist/interview-questions/deep-learning/gradient-descent-method/#shrt-collapse-5)

Gradient checking is used for debugging the gradient descent algorithm and to make sure that we have a correct implementation.

 That is, when we implement the gradient descent method for the complex neural network, even with buggy implementations, the network will learn something.

 But the buggy implementation will not be as optimal as a bug-free implementation. So to ensure that we have the bug free implementation of gradient descent we perform gradient checking.







##### [What are numerical and analytical gradients?](https://avatto.in/data-scientist/interview-questions/deep-learning/gradient-descent-method/page/2/#shrt-collapse-1)

Analytical gradients are the gradients we calculated through backpropagation and the numerical gradients are the numerical approximation to the gradients.









##### [Explain gradient checking.](https://avatto.in/data-scientist/interview-questions/deep-learning/gradient-descent-method/page/2/#shrt-collapse-2)

 In gradient checking, first, we compute the analytical and approximated numerical gradients. Then we compare the analytical and numerical gradients. If they are not the same then there is an error with our implementation.

 we don’t have to check whether analytical and numerical gradients are exactly the same since the numerical gradient is just an approximation. So, we compute the difference between the analytical and numerical gradients and if their difference is very small say 1e-7 then our implementation is correct else we have a buggy implementation.









##### [How can we set the learning rate adaptively?](https://avatto.in/data-scientist/interview-questions/deep-learning/gradient-descent-method/page/4/#shrt-collapse-2)

We can set the learning rate adaptively using adagrad. Using adagrad method, we assign a high learning rate when the previous gradient value is low and we assign a low learning rate when the previous gradient value is high. This makes the learning rate to change adaptively based on the past gradient updates.









##### [Can we get rid of the learning rate?](https://avatto.in/data-scientist/interview-questions/deep-learning/gradient-descent-method/page/4/#shrt-collapse-3)

Yes, we can get rid of the learning date using adadelta.





**What are Gradient Descent and Stochastic Gradient Descent? And what is the difference between them?**

Imagine you are walking down a hill from peak, what is your next step? Gradient Descent (GD) and Stochastic Gradient Descent (SGD) are 2 common ways of calculating next step from the current position.

GD and SGD are optimizers in Deep Learning by slowly nudging weights (the parameters of a model) toward better results. In practice, you can train and compare a fully-connected network using GD and SGD. The SGD optimized model would be more accurate than GD along with less training time required.

At each step, SGD takes a very small step instead of a large step, and uses a tiny random sample instead of the complete data. SGD is efficient because of smaller data set at each time and compensates by do it a lot of times. You can progressively train deeper and more accurate models using TensorFlow function [tf.contrib.keras.optimizers.SGD](https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/keras/optimizers/SGD).







**What is Backpropagation?**

Backpropagation is commonly used by gradient-based optimizers to adjust the weight of neurons in **multi-layered neural networks**.



Backpropagation involves the following steps:

1. When an input vector is presented to the network, it is propagated forward through the network, layer by layer, until it reaches the output layer.
2. The loss function calculates the difference (called “error”) between the network output and its expected output.
3. The resulting error value is calculated for each of the neurons in the output layer.
4. The error values are then propagated from the output back through the network, until each neuron has an associated error value that reflects its contribution to the original output.
5. Backpropagation uses these error values to calculate the gradient of the loss function.
6. This gradient is fed to the optimization method, which in turn uses it to update the weights, in an attempt to minimize the loss function.

Often, normalization of input vectors could improve the performance of models.



