# ch5

결정트리(DecisionTreeClassifier)

데이터를 잘 나눌수 있는 질문을 찾는다면 계속 질문을 추가해서 분류 정확도를 높일수 있다.



구성요소

노드:훈련 데이터의 특성에 대한 테스트를 표현

가지: 테스트의 결과(True, False)를 나타내며 일반적으로 하나의 노드는 2개의 가지를 가진다. 

![image-20230707004306713](C:\Users\User\AppData\Roaming\Typora\typora-user-images\image-20230707004306713.png)

불순도: 결정 트리가 최적의 질문을 찾기 위한 기준이다. 

지니 불순도(gini): 1-(음성 클래스 비율  *^2 + 양성클래스 비율*  ^2)



정보이득: 부모와 자식 사이의 불순도 차이가 큰 트리를 만든다.

엔트로피 불순도: ![img](https://blog.kakaocdn.net/dn/pL6pO/btqwVDN1V94/TYgn5iFrPTfgdVwZhxVKl1/img.png)

가지치기: 가지의 최대갯수를 한정해줌 (만약 계속해서 가지가 늘어나면 훈련세트의 정확도는 높아지겠지만 테스트세트는 낮아지는걸 방지)



특성중요도: 결정트리에 사용된 특성이 불순도를 감소하는데 기여한 정도를 나타내는 값



교차 검증과 그리드 서치

훈련세트 검증세트 테스트세트= 6:2:2

검증세트: 하이퍼파라미터 튜닝을 위해 모델을 평가할때, 테이스 세트를 사용하지 않기 위해 훈련 세트에서 다시 떼어 낸 데이터 세트



하이퍼파라미터 튜닝:

- 최적의 딥러닝 모델 구현을 위해 학습률이나 배치크기, 훈련 반복 횟수, 가중치 초기화 방법 등 인간의 선험적 지식을 기반으로 딥러닝 모델에 설정하는 변수
- ![image-20230707010324747](C:\Users\User\AppData\Roaming\Typora\typora-user-images\image-20230707010324747.png)

![image-20230707010433473](C:\Users\User\AppData\Roaming\Typora\typora-user-images\image-20230707010433473.png)





교차검증: 검증세트를 떼어 내어 평가하는 과정의 반복





정형데이터: 어떠한 구조로 되어있는 데이터

ex)csv,데이터베이서, 엑셀

비정형 데이터: 데이터베이스나 엑셀로 표현하기 어려운 데이터

ex) 텍스트 데이터, 디지털카메라로 찍은 사진, 핸드폰으로 듣는 음악

앙상블 알고리즘: 정형데이터를 다루기 쉬운 알고리즘

랜덤포레스트: 각트리들을 훈련하기 위해 데이터를 랜덤하게 만든다,

이때 입력한 훈련 데이터에서 랜덤하게 샘플을 추출하여 훈련데이터를 만드는 방법을 사용한다.(샘플은 중복추출가능(부트스트랩))



엑스트라 트리: 결정트리의 노드를 일정하게 분할함 



```python
from sklearn.ensemble import ExtraTreesClassifier

et = ExtraTreesClassifier(n_jobs=-1, random_state=42)
scores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs=-1)

print(np.mean(scores['train_score']), np.mean(scores['test_score']))
```





그레이디언트 부스팅: 이전 트리의 손실을 보완하는 식으로 얕은 결정 트리를 연속하여 추가한다



```python
from sklearn.ensemble import GradientBoostingClassifier

gb = GradientBoostingClassifier(random_state=42)
scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)

print(np.mean(scores['train_score']), np.mean(scores['test_score']))
```

히스토그램 기반 그레이디언트 부스팅: 훈련데이터 256개 정수 구간으로 나누어 빠르게 성능을냄 

```python
from sklearn.ensemble import HistGradientBoostingClassifier

hgb = HistGradientBoostingClassifier(random_state=42)
scores = cross_validate(hgb, train_input, train_target, return_train_score=True, n_jobs=-1)

print(np.mean(scores['train_score']), np.mean(scores['test_score']))
```





